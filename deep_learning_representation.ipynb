{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Dense, TimeDistributed, Input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.engine.topology import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 1024\n",
    "\n",
    "from keras_rmac.get_regions import get_size_vgg_feat_map, rmac_regions\n",
    "from keras_rmac.RoiPooling import RoiPooling\n",
    "from keras_rmac.utils import preprocess_image\n",
    "\n",
    "\n",
    "def generate_model(input_shape, num_rois, model_summary=False):\n",
    "\n",
    "    # Load VGG16\n",
    "    vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    # The output size of VGG16 is 7x7x512\n",
    "    \n",
    "    # freeze the layers\n",
    "    for layer in vgg16_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    print(\"Number of Region of Interests: \", num_rois)\n",
    "    # Generate input layer for Region of Interests\n",
    "    in_roi = Input(shape=(num_rois, 4), name='input_roi')\n",
    "    \n",
    "    # Use the RoiPooling layer which picks the regions and generate max over the regions\n",
    "    x = RoiPooling([1], num_rois)([vgg16_model.layers[-5].output, in_roi])\n",
    "    model = Model([vgg16_model.input, in_roi], x)\n",
    "    if model_summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rep(img_path, img_size=224, model_summary=False):\n",
    "    img = load_img(img_path, target_size=(img_size, img_size))\n",
    "\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Mean substraction\n",
    "    x = preprocess_image(x)\n",
    "\n",
    "    Wmap, Hmap = get_size_vgg_feat_map(x.shape[2], x.shape[1])\n",
    "    regions = rmac_regions(Wmap, Hmap, 3)\n",
    "    print('Loading Model...')\n",
    "    model = generate_model((x.shape[1], x.shape[2], x.shape[3]),\n",
    "                           len(regions), model_summary)\n",
    "\n",
    "    # Compute vector\n",
    "    print('Generating Vector...')\n",
    "    RMAC = model.predict([x, np.expand_dims(regions, axis=0)])\n",
    "    return np.sum(RMAC, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sherly/keras_rmac/get_regions.py:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  b = (W - wl) / (l + Wd - 1)\n",
      "/home/sherly/keras_rmac/get_regions.py:45: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  b = (H-wl)/(l+Hd-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_roi (InputLayer)          (None, 14, 4)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roi_pooling_1 (RoiPooling)      (None, 14, 512)      0           block4_pool[0][0]                \n",
      "                                                                 input_roi[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,635,264\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,635,264\n",
      "__________________________________________________________________________________________________\n",
      "Generating Vector...\n"
     ]
    }
   ],
   "source": [
    "vec = generate_rep(\"images/100000.jpg\", model_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import time\n",
    "\n",
    "def generate_rmac_vectors(image_dir, output_path):\n",
    "    rmac_vec = {}\n",
    "\n",
    "    img_files = glob(image_dir + \"*\")\n",
    "    print(\"Number of images to generate for: \", len(img_files))\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for idx, im in enumerate(img_files):\n",
    "            imfile = im.split(\"/\")[-1]\n",
    "            print(\"Generating for im: {} file: {}\".format(idx, imfile))\n",
    "            rmac_vec[imfile] = generate_rep(im, 224).tolist()\n",
    "\n",
    "        json.dump(rmac_vec, f)\n",
    "        \n",
    "    return rmac_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images to generate for:  24\n",
      "Generating for im: 0 file: 100600.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 1 file: 100301.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 2 file: 100100.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 3 file: 100900.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 4 file: 100503.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 5 file: 100700.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 6 file: 100001.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 7 file: 100701.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 8 file: 100101.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 9 file: 100200.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 10 file: 100002.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 11 file: 100501.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 12 file: 100300.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 13 file: 100401.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 14 file: 100000.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 15 file: 100400.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 16 file: 100601.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 17 file: 100901.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 18 file: 100302.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 19 file: 100201.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 20 file: 100800.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 21 file: 100801.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 22 file: 100500.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n",
      "Generating for im: 23 file: 100502.jpg\n",
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "file = \"rmac_vectors_{}.txt\".format(t)\n",
    "image_dir = \"subset_image/100\"\n",
    "\n",
    "rmac_vectors = generate_rmac_vectors(image_dir, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similar_images(imgpath, image_dict):\n",
    "    imfile = imgpath.split(\"/\")[-1]\n",
    "    # check if the image has pre-generated vector else generate it\n",
    "    if imfile in image_dict.keys():\n",
    "        img_vec = image_dict[imfile]\n",
    "    else:\n",
    "        img_vec = generate_rep(imgpath)\n",
    "\n",
    "    similarities = {}\n",
    "    for k, v in image_dict.items():\n",
    "        similarities[k] = cosine_similarity(\n",
    "            np.array(img_vec),\n",
    "            np.array(v))\n",
    "\n",
    "    # Return the top n similar images\n",
    "    most_sim = dict(sorted(similarities.items(),\n",
    "                key=lambda x:x[1],\n",
    "                reverse=True)[:5]).keys()\n",
    "    \n",
    "    return most_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['100300.jpg', '100400.jpg', '100301.jpg', '100302.jpg', '100503.jpg'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_images('100300.jpg', rmac_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sherly/keras_rmac/get_regions.py:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  b = (W - wl) / (l + Wd - 1)\n",
      "/home/sherly/keras_rmac/get_regions.py:45: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  b = (H-wl)/(l+Hd-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "Number of Region of Interests:  14\n",
      "Generating Vector...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['100300.jpg', '100000.jpg', '100502.jpg', '100400.jpg', '100503.jpg'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_images('subset_image/101300.jpg', rmac_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
